{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üöÄ CekAjaYuk - Complete Model Training\n",
    "## Deteksi Lowongan Kerja Palsu dengan Machine Learning & Deep Learning\n",
    "\n",
    "**Notebook ini menggabungkan semua proses training:**\n",
    "1. üìÇ Dataset Preparation & Validation\n",
    "2. üîß Data Preprocessing & Feature Extraction\n",
    "3. üå≤ Random Forest Training & Optimization\n",
    "4. üß† CNN/TensorFlow Deep Learning Training\n",
    "5. üìä Model Evaluation & Export\n",
    "\n",
    "---\n",
    "### üìã Requirements:\n",
    "- Dataset: 800 gambar (400 fake + 400 genuine)\n",
    "- Python 3.7+\n",
    "- Libraries: scikit-learn, tensorflow, opencv, pillow\n",
    "\n",
    "### üéØ Output:\n",
    "- `random_forest_production.pkl`\n",
    "- `cnn_production.h5`\n",
    "- `feature_scaler_production.pkl`\n",
    "- `text_vectorizer_production.pkl`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## üîß 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_packages"
   },
   "outputs": [],
   "source": [
    "# Install required packages for Google Colab\n",
    "!pip install opencv-python-headless\n",
    "!pip install scikit-learn\n",
    "!pip install tensorflow\n",
    "!pip install pillow\n",
    "!pip install matplotlib seaborn\n",
    "!pip install joblib\n",
    "\n",
    "print(\"‚úÖ All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_libraries"
   },
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import json\n",
    "import joblib\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    precision_score, recall_score, f1_score, roc_auc_score\n",
    ")\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, MaxPooling2D, Dense, Flatten, Dropout, \n",
    "    GlobalAveragePooling2D, BatchNormalization\n",
    ")\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "print(\"üìö All libraries imported successfully!\")\n",
    "print(f\"üî• TensorFlow version: {tf.__version__}\")\n",
    "print(f\"üêç Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset_upload"
   },
   "source": [
    "## üìÇ 2. Dataset Upload & Preparation\n",
    "\n",
    "### üìã Instructions:\n",
    "1. **Zip your dataset** dengan struktur:\n",
    "   ```\n",
    "   dataset.zip\n",
    "   ‚îú‚îÄ‚îÄ fake/\n",
    "   ‚îÇ   ‚îú‚îÄ‚îÄ fake_job_001.jpg\n",
    "   ‚îÇ   ‚îú‚îÄ‚îÄ fake_job_002.jpg\n",
    "   ‚îÇ   ‚îî‚îÄ‚îÄ ... (400 files)\n",
    "   ‚îî‚îÄ‚îÄ genuine/\n",
    "       ‚îú‚îÄ‚îÄ genuine_job_001.jpg\n",
    "       ‚îú‚îÄ‚îÄ genuine_job_002.jpg\n",
    "       ‚îî‚îÄ‚îÄ ... (400 files)\n",
    "   ```\n",
    "2. **Upload** file `dataset.zip` ke Colab\n",
    "3. **Run** cell di bawah untuk extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_dataset"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"üì§ Upload your dataset.zip file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Extract dataset\n",
    "for filename in uploaded.keys():\n",
    "    if filename.endswith('.zip'):\n",
    "        print(f\"üì¶ Extracting {filename}...\")\n",
    "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall('.')\n",
    "        print(f\"‚úÖ {filename} extracted successfully!\")\n",
    "        break\n",
    "else:\n",
    "    print(\"‚ùå No zip file found. Please upload dataset.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "validate_dataset"
   },
   "outputs": [],
   "source": [
    "# Validate dataset structure\n",
    "def validate_dataset(dataset_dir='dataset'):\n",
    "    \"\"\"Validate dataset structure and count files\"\"\"\n",
    "    dataset_path = Path(dataset_dir)\n",
    "    \n",
    "    if not dataset_path.exists():\n",
    "        print(f\"‚ùå Dataset directory '{dataset_dir}' not found!\")\n",
    "        return False\n",
    "    \n",
    "    fake_dir = dataset_path / 'fake'\n",
    "    genuine_dir = dataset_path / 'genuine'\n",
    "    \n",
    "    if not fake_dir.exists():\n",
    "        print(f\"‚ùå Fake directory not found: {fake_dir}\")\n",
    "        return False\n",
    "        \n",
    "    if not genuine_dir.exists():\n",
    "        print(f\"‚ùå Genuine directory not found: {genuine_dir}\")\n",
    "        return False\n",
    "    \n",
    "    # Count files\n",
    "    fake_files = list(fake_dir.glob('*.[jJ][pP][gG]')) + list(fake_dir.glob('*.[pP][nN][gG]'))\n",
    "    genuine_files = list(genuine_dir.glob('*.[jJ][pP][gG]')) + list(genuine_dir.glob('*.[pP][nN][gG]'))\n",
    "    \n",
    "    print(f\"üìä Dataset Validation:\")\n",
    "    print(f\"   üìÅ Fake samples: {len(fake_files)}\")\n",
    "    print(f\"   üìÅ Genuine samples: {len(genuine_files)}\")\n",
    "    print(f\"   üìÅ Total samples: {len(fake_files) + len(genuine_files)}\")\n",
    "    \n",
    "    if len(fake_files) == 0 or len(genuine_files) == 0:\n",
    "        print(\"‚ùå Dataset validation failed: Empty directories\")\n",
    "        return False\n",
    "    \n",
    "    print(\"‚úÖ Dataset validation passed!\")\n",
    "    return True\n",
    "\n",
    "# Validate the uploaded dataset\n",
    "dataset_valid = validate_dataset()\n",
    "\n",
    "if not dataset_valid:\n",
    "    print(\"\\nüîÑ Trying alternative dataset paths...\")\n",
    "    # Try different possible paths\n",
    "    for possible_path in ['data', 'datasets', '.']:\n",
    "        if validate_dataset(possible_path):\n",
    "            dataset_valid = True\n",
    "            break\n",
    "\n",
    "if not dataset_valid:\n",
    "    print(\"\\n‚ùå Dataset validation failed. Please check your upload.\")\n",
    "else:\n",
    "    print(\"\\nüéâ Ready to proceed with training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feature_extraction"
   },
   "source": [
    "## üîß 3. Feature Extraction & Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feature_extractor_class"
   },
   "outputs": [],
   "source": [
    "class ImageFeatureExtractor:\n",
    "    \"\"\"Extract features from job posting images\"\"\"\n",
    "    \n",
    "    def __init__(self, img_size=(224, 224)):\n",
    "        self.img_size = img_size\n",
    "        self.supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}\n",
    "        \n",
    "    def load_and_preprocess_image(self, image_path):\n",
    "        \"\"\"Load and preprocess single image\"\"\"\n",
    "        try:\n",
    "            # Load image\n",
    "            img = cv2.imread(str(image_path))\n",
    "            if img is None:\n",
    "                return None\n",
    "                \n",
    "            # Convert BGR to RGB\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Resize\n",
    "            img = cv2.resize(img, self.img_size)\n",
    "            \n",
    "            # Normalize\n",
    "            img = img.astype(np.float32) / 255.0\n",
    "            \n",
    "            return img\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def extract_visual_features(self, img):\n",
    "        \"\"\"Extract visual features from image\"\"\"\n",
    "        if img is None:\n",
    "            return np.zeros(10)  # Return zero features if image is None\n",
    "            \n",
    "        features = []\n",
    "        \n",
    "        # Convert to different color spaces\n",
    "        gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "        hsv = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2HSV)\n",
    "        \n",
    "        # 1. Color statistics\n",
    "        features.extend([\n",
    "            np.mean(img[:,:,0]),  # Red mean\n",
    "            np.mean(img[:,:,1]),  # Green mean\n",
    "            np.mean(img[:,:,2]),  # Blue mean\n",
    "            np.std(img[:,:,0]),   # Red std\n",
    "            np.std(img[:,:,1]),   # Green std\n",
    "            np.std(img[:,:,2])    # Blue std\n",
    "        ])\n",
    "        \n",
    "        # 2. Brightness and contrast\n",
    "        features.extend([\n",
    "            np.mean(gray),        # Brightness\n",
    "            np.std(gray),         # Contrast\n",
    "        ])\n",
    "        \n",
    "        # 3. Edge density (Canny edges)\n",
    "        edges = cv2.Canny(gray, 50, 150)\n",
    "        edge_density = np.sum(edges > 0) / (edges.shape[0] * edges.shape[1])\n",
    "        features.append(edge_density)\n",
    "        \n",
    "        # 4. Texture (using Laplacian variance)\n",
    "        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "        features.append(laplacian_var)\n",
    "        \n",
    "        return np.array(features)\n",
    "    \n",
    "    def load_dataset(self, dataset_dir='dataset'):\n",
    "        \"\"\"Load complete dataset with features and labels\"\"\"\n",
    "        dataset_path = Path(dataset_dir)\n",
    "        \n",
    "        images = []\n",
    "        features = []\n",
    "        labels = []\n",
    "        filenames = []\n",
    "        \n",
    "        # Load fake samples\n",
    "        fake_dir = dataset_path / 'fake'\n",
    "        fake_files = list(fake_dir.glob('*.[jJ][pP][gG]')) + list(fake_dir.glob('*.[pP][nN][gG]'))\n",
    "        \n",
    "        print(f\"üìÇ Loading {len(fake_files)} fake samples...\")\n",
    "        for i, img_path in enumerate(fake_files):\n",
    "            img = self.load_and_preprocess_image(img_path)\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "                features.append(self.extract_visual_features(img))\n",
    "                labels.append(0)  # 0 = fake\n",
    "                filenames.append(img_path.name)\n",
    "            \n",
    "            if (i + 1) % 50 == 0:\n",
    "                print(f\"   Processed {i + 1}/{len(fake_files)} fake samples\")\n",
    "        \n",
    "        # Load genuine samples\n",
    "        genuine_dir = dataset_path / 'genuine'\n",
    "        genuine_files = list(genuine_dir.glob('*.[jJ][pP][gG]')) + list(genuine_dir.glob('*.[pP][nN][gG]'))\n",
    "        \n",
    "        print(f\"üìÇ Loading {len(genuine_files)} genuine samples...\")\n",
    "        for i, img_path in enumerate(genuine_files):\n",
    "            img = self.load_and_preprocess_image(img_path)\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "                features.append(self.extract_visual_features(img))\n",
    "                labels.append(1)  # 1 = genuine\n",
    "                filenames.append(img_path.name)\n",
    "            \n",
    "            if (i + 1) % 50 == 0:\n",
    "                print(f\"   Processed {i + 1}/{len(genuine_files)} genuine samples\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ Dataset loaded successfully!\")\n",
    "        print(f\"   üìä Total samples: {len(images)}\")\n",
    "        print(f\"   üìä Fake samples: {sum(1 for l in labels if l == 0)}\")\n",
    "        print(f\"   üìä Genuine samples: {sum(1 for l in labels if l == 1)}\")\n",
    "        \n",
    "        return {\n",
    "            'images': np.array(images),\n",
    "            'features': np.array(features),\n",
    "            'labels': np.array(labels),\n",
    "            'filenames': filenames\n",
    "        }\n",
    "\n",
    "# Initialize feature extractor\n",
    "feature_extractor = ImageFeatureExtractor()\n",
    "print(\"üîß Feature extractor initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_dataset"
   },
   "outputs": [],
   "source": [
    "# Load and process the dataset\n",
    "print(\"üöÄ Starting dataset loading and feature extraction...\")\n",
    "print(\"‚è±Ô∏è  This may take several minutes depending on dataset size...\\n\")\n",
    "\n",
    "# Load dataset\n",
    "dataset = feature_extractor.load_dataset('dataset')\n",
    "\n",
    "# Extract components\n",
    "X_images = dataset['images']\n",
    "X_features = dataset['features']\n",
    "y = dataset['labels']\n",
    "filenames = dataset['filenames']\n",
    "\n",
    "print(f\"\\nüìä Dataset Summary:\")\n",
    "print(f\"   üñºÔ∏è  Image shape: {X_images.shape}\")\n",
    "print(f\"   üî¢ Feature shape: {X_features.shape}\")\n",
    "print(f\"   üè∑Ô∏è  Labels shape: {y.shape}\")\n",
    "print(f\"   üìÅ Files processed: {len(filenames)}\")\n",
    "\n",
    "# Data distribution\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(f\"\\nüìà Class Distribution:\")\n",
    "for label, count in zip(unique, counts):\n",
    "    class_name = 'Fake' if label == 0 else 'Genuine'\n",
    "    percentage = (count / len(y)) * 100\n",
    "    print(f\"   {class_name}: {count} samples ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_split"
   },
   "source": [
    "## üîÑ 4. Data Splitting & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "split_data"
   },
   "outputs": [],
   "source": [
    "# Split data for training and testing\n",
    "print(\"üîÑ Splitting dataset...\")\n",
    "\n",
    "# Split images and features\n",
    "X_img_train, X_img_test, X_feat_train, X_feat_test, y_train, y_test = train_test_split(\n",
    "    X_images, X_features, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Further split training data for validation\n",
    "X_img_train, X_img_val, X_feat_train, X_feat_val, y_train, y_val = train_test_split(\n",
    "    X_img_train, X_feat_train, y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"üìä Data Split Summary:\")\n",
    "print(f\"   üèãÔ∏è  Training: {len(X_img_train)} samples\")\n",
    "print(f\"   ‚úÖ Validation: {len(X_img_val)} samples\")\n",
    "print(f\"   üß™ Testing: {len(X_img_test)} samples\")\n",
    "\n",
    "# Scale features for Random Forest\n",
    "print(\"\\n‚öôÔ∏è Scaling features...\")\n",
    "scaler = StandardScaler()\n",
    "X_feat_train_scaled = scaler.fit_transform(X_feat_train)\n",
    "X_feat_val_scaled = scaler.transform(X_feat_val)\n",
    "X_feat_test_scaled = scaler.transform(X_feat_test)\n",
    "\n",
    "print(\"‚úÖ Data preprocessing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "random_forest"
   },
   "source": [
    "## üå≤ 5. Random Forest Training & Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rf_training"
   },
   "outputs": [],
   "source": [
    "# Random Forest Training with Hyperparameter Tuning\n",
    "print(\"üå≤ Training Random Forest Classifier...\")\n",
    "\n",
    "# Define parameter grid for GridSearch\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Perform GridSearch\n",
    "print(\"üîç Performing hyperparameter optimization...\")\n",
    "print(\"‚è±Ô∏è  This may take 10-15 minutes...\")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    rf, param_grid, \n",
    "    cv=5, \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_feat_train_scaled, y_train)\n",
    "\n",
    "# Get best model\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "print(f\"\\nüéØ Best Random Forest Parameters:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"   {param}: {value}\")\n",
    "\n",
    "print(f\"\\nüìä Best Cross-Validation Score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rf_evaluation"
   },
   "outputs": [],
   "source": [
    "# Evaluate Random Forest\n",
    "print(\"üìä Evaluating Random Forest Model...\")\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = best_rf.predict(X_feat_train_scaled)\n",
    "y_val_pred = best_rf.predict(X_feat_val_scaled)\n",
    "y_test_pred = best_rf.predict(X_feat_test_scaled)\n",
    "\n",
    "# Prediction probabilities\n",
    "y_train_proba = best_rf.predict_proba(X_feat_train_scaled)[:, 1]\n",
    "y_val_proba = best_rf.predict_proba(X_feat_val_scaled)[:, 1]\n",
    "y_test_proba = best_rf.predict_proba(X_feat_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "val_acc = accuracy_score(y_val, y_val_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "train_auc = roc_auc_score(y_train, y_train_proba)\n",
    "val_auc = roc_auc_score(y_val, y_val_proba)\n",
    "test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "print(f\"\\nüéØ Random Forest Performance:\")\n",
    "print(f\"   üìà Training Accuracy: {train_acc:.4f}\")\n",
    "print(f\"   üìà Validation Accuracy: {val_acc:.4f}\")\n",
    "print(f\"   üìà Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"   üìà Training AUC: {train_auc:.4f}\")\n",
    "print(f\"   üìà Validation AUC: {val_auc:.4f}\")\n",
    "print(f\"   üìà Test AUC: {test_auc:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(f\"\\nüìã Detailed Classification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=['Fake', 'Genuine']))\n",
    "\n",
    "# Feature importance\n",
    "feature_names = [\n",
    "    'Red_Mean', 'Green_Mean', 'Blue_Mean', 'Red_Std', 'Green_Std', 'Blue_Std',\n",
    "    'Brightness', 'Contrast', 'Edge_Density', 'Texture_Variance'\n",
    "]\n",
    "\n",
    "importances = best_rf.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(f\"\\nüîç Top 5 Most Important Features:\")\n",
    "for idx, row in feature_importance_df.head().iterrows():\n",
    "    print(f\"   {row['Feature']}: {row['Importance']:.4f}\")\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feature_importance_df, x='Importance', y='Feature')\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnn_training"
   },
   "source": [
    "## üß† 6. CNN/Deep Learning Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cnn_model"
   },
   "outputs": [],
   "source": [
    "# Build CNN Model\n",
    "def create_cnn_model(input_shape=(224, 224, 3)):\n",
    "    \"\"\"Create CNN model for job posting classification\"\"\"\n",
    "    model = Sequential([\n",
    "        # First Convolutional Block\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Second Convolutional Block\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Third Convolutional Block\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Fourth Convolutional Block\n",
    "        Conv2D(256, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        # Dense Layers\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Output Layer\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and compile model\n",
    "print(\"üß† Creating CNN Model...\")\n",
    "cnn_model = create_cnn_model()\n",
    "\n",
    "# Compile model\n",
    "cnn_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Model summary\n",
    "print(\"\\nüìã CNN Model Architecture:\")\n",
    "cnn_model.summary()\n",
    "\n",
    "# Count parameters\n",
    "total_params = cnn_model.count_params()\n",
    "print(f\"\\nüìä Total Parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data_augmentation"
   },
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "print(\"üîÑ Setting up data augmentation...\")\n",
    "\n",
    "# Training data generator with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation data generator (no augmentation)\n",
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "# Fit generators\n",
    "train_generator = train_datagen.flow(X_img_train, y_train, batch_size=32)\n",
    "val_generator = val_datagen.flow(X_img_val, y_val, batch_size=32)\n",
    "\n",
    "print(\"‚úÖ Data augmentation setup completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cnn_training_process"
   },
   "outputs": [],
   "source": [
    "# Training Callbacks\n",
    "print(\"‚öôÔ∏è Setting up training callbacks...\")\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'best_cnn_model.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nüöÄ Starting CNN training...\")\n",
    "print(\"‚è±Ô∏è  This may take 30-60 minutes depending on GPU availability...\")\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(X_img_train) // 32,\n",
    "    epochs=50,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(X_img_val) // 32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ CNN training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cnn_evaluation"
   },
   "outputs": [],
   "source": [
    "# Evaluate CNN Model\n",
    "print(\"üìä Evaluating CNN Model...\")\n",
    "\n",
    "# Load best model\n",
    "best_cnn = tf.keras.models.load_model('best_cnn_model.h5')\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_cnn = (best_cnn.predict(X_img_train) > 0.5).astype(int).flatten()\n",
    "y_val_pred_cnn = (best_cnn.predict(X_img_val) > 0.5).astype(int).flatten()\n",
    "y_test_pred_cnn = (best_cnn.predict(X_img_test) > 0.5).astype(int).flatten()\n",
    "\n",
    "# Prediction probabilities\n",
    "y_train_proba_cnn = best_cnn.predict(X_img_train).flatten()\n",
    "y_val_proba_cnn = best_cnn.predict(X_img_val).flatten()\n",
    "y_test_proba_cnn = best_cnn.predict(X_img_test).flatten()\n",
    "\n",
    "# Calculate metrics\n",
    "train_acc_cnn = accuracy_score(y_train, y_train_pred_cnn)\n",
    "val_acc_cnn = accuracy_score(y_val, y_val_pred_cnn)\n",
    "test_acc_cnn = accuracy_score(y_test, y_test_pred_cnn)\n",
    "\n",
    "train_auc_cnn = roc_auc_score(y_train, y_train_proba_cnn)\n",
    "val_auc_cnn = roc_auc_score(y_val, y_val_proba_cnn)\n",
    "test_auc_cnn = roc_auc_score(y_test, y_test_proba_cnn)\n",
    "\n",
    "print(f\"\\nüéØ CNN Performance:\")\n",
    "print(f\"   üìà Training Accuracy: {train_acc_cnn:.4f}\")\n",
    "print(f\"   üìà Validation Accuracy: {val_acc_cnn:.4f}\")\n",
    "print(f\"   üìà Test Accuracy: {test_acc_cnn:.4f}\")\n",
    "print(f\"   üìà Training AUC: {train_auc_cnn:.4f}\")\n",
    "print(f\"   üìà Validation AUC: {val_auc_cnn:.4f}\")\n",
    "print(f\"   üìà Test AUC: {test_auc_cnn:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(f\"\\nüìã Detailed Classification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_test_pred_cnn, target_names=['Fake', 'Genuine']))\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Learning rate plot (if available)\n",
    "plt.subplot(1, 3, 3)\n",
    "if 'lr' in history.history:\n",
    "    plt.plot(history.history['lr'])\n",
    "    plt.title('Learning Rate')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.text(0.5, 0.5, 'Learning Rate\\nNot Recorded', \n",
    "             ha='center', va='center', transform=plt.gca().transAxes)\n",
    "    plt.title('Learning Rate')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_comparison"
   },
   "source": [
    "## üìä 7. Model Comparison & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "compare_models"
   },
   "outputs": [],
   "source": [
    "# Compare model performances\n",
    "print(\"üìä Model Comparison Summary:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "comparison_data = {\n",
    "    'Model': ['Random Forest', 'CNN'],\n",
    "    'Test_Accuracy': [test_acc, test_acc_cnn],\n",
    "    'Test_AUC': [test_auc, test_auc_cnn],\n",
    "    'Val_Accuracy': [val_acc, val_acc_cnn],\n",
    "    'Val_AUC': [val_auc, val_auc_cnn]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "# Determine best model\n",
    "best_model_idx = comparison_df['Test_Accuracy'].idxmax()\n",
    "best_model_name = comparison_df.loc[best_model_idx, 'Model']\n",
    "best_accuracy = comparison_df.loc[best_model_idx, 'Test_Accuracy']\n",
    "\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
    "print(f\"üéØ Best Test Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "# Ensemble prediction (average of both models)\n",
    "print(\"\\nü§ù Creating Ensemble Prediction...\")\n",
    "ensemble_proba = (y_test_proba + y_test_proba_cnn) / 2\n",
    "ensemble_pred = (ensemble_proba > 0.5).astype(int)\n",
    "\n",
    "ensemble_acc = accuracy_score(y_test, ensemble_pred)\n",
    "ensemble_auc = roc_auc_score(y_test, ensemble_proba)\n",
    "\n",
    "print(f\"üéØ Ensemble Test Accuracy: {ensemble_acc:.4f}\")\n",
    "print(f\"üéØ Ensemble Test AUC: {ensemble_auc:.4f}\")\n",
    "\n",
    "# Add ensemble to comparison\n",
    "comparison_data['Model'].append('Ensemble')\n",
    "comparison_data['Test_Accuracy'].append(ensemble_acc)\n",
    "comparison_data['Test_AUC'].append(ensemble_auc)\n",
    "comparison_data['Val_Accuracy'].append(np.nan)  # Not calculated for ensemble\n",
    "comparison_data['Val_AUC'].append(np.nan)\n",
    "\n",
    "final_comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\nüìà Final Model Comparison:\")\n",
    "print(final_comparison_df.round(4))\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Accuracy comparison\n",
    "plt.subplot(2, 2, 1)\n",
    "models = ['Random Forest', 'CNN', 'Ensemble']\n",
    "accuracies = [test_acc, test_acc_cnn, ensemble_acc]\n",
    "colors = ['skyblue', 'lightcoral', 'lightgreen']\n",
    "plt.bar(models, accuracies, color=colors)\n",
    "plt.title('Test Accuracy Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "for i, v in enumerate(accuracies):\n",
    "    plt.text(i, v + 0.01, f'{v:.3f}', ha='center')\n",
    "\n",
    "# AUC comparison\n",
    "plt.subplot(2, 2, 2)\n",
    "aucs = [test_auc, test_auc_cnn, ensemble_auc]\n",
    "plt.bar(models, aucs, color=colors)\n",
    "plt.title('Test AUC Comparison')\n",
    "plt.ylabel('AUC')\n",
    "plt.ylim(0, 1)\n",
    "for i, v in enumerate(aucs):\n",
    "    plt.text(i, v + 0.01, f'{v:.3f}', ha='center')\n",
    "\n",
    "# Confusion Matrix for best model\n",
    "plt.subplot(2, 2, 3)\n",
    "if best_model_name == 'Random Forest':\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "else:\n",
    "    cm = confusion_matrix(y_test, y_test_pred_cnn)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Fake', 'Genuine'], \n",
    "            yticklabels=['Fake', 'Genuine'])\n",
    "plt.title(f'Confusion Matrix - {best_model_name}')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "# Performance metrics radar chart data\n",
    "plt.subplot(2, 2, 4)\n",
    "metrics_rf = [test_acc, test_auc, precision_score(y_test, y_test_pred), recall_score(y_test, y_test_pred)]\n",
    "metrics_cnn = [test_acc_cnn, test_auc_cnn, precision_score(y_test, y_test_pred_cnn), recall_score(y_test, y_test_pred_cnn)]\n",
    "metrics_names = ['Accuracy', 'AUC', 'Precision', 'Recall']\n",
    "\n",
    "x = np.arange(len(metrics_names))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, metrics_rf, width, label='Random Forest', alpha=0.8)\n",
    "plt.bar(x + width/2, metrics_cnn, width, label='CNN', alpha=0.8)\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Model Performance Metrics')\n",
    "plt.xticks(x, metrics_names, rotation=45)\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_export"
   },
   "source": [
    "## üíæ 8. Model Export & Production Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export_models"
   },
   "outputs": [],
   "source": [
    "# Export trained models for production\n",
    "print(\"üíæ Exporting models for production...\")\n",
    "\n",
    "# Create models directory\n",
    "os.makedirs('production_models', exist_ok=True)\n",
    "\n",
    "# Export Random Forest\n",
    "rf_filename = 'production_models/random_forest_production.pkl'\n",
    "joblib.dump(best_rf, rf_filename)\n",
    "print(f\"‚úÖ Random Forest saved: {rf_filename}\")\n",
    "\n",
    "# Export Feature Scaler\n",
    "scaler_filename = 'production_models/feature_scaler_production.pkl'\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "print(f\"‚úÖ Feature Scaler saved: {scaler_filename}\")\n",
    "\n",
    "# Export CNN Model\n",
    "cnn_filename = 'production_models/cnn_production.h5'\n",
    "best_cnn.save(cnn_filename)\n",
    "print(f\"‚úÖ CNN Model saved: {cnn_filename}\")\n",
    "\n",
    "# Create feature names file\n",
    "feature_names_file = 'production_models/feature_names_production.txt'\n",
    "with open(feature_names_file, 'w') as f:\n",
    "    for name in feature_names:\n",
    "        f.write(f\"{name}\\n\")\n",
    "print(f\"‚úÖ Feature names saved: {feature_names_file}\")\n",
    "\n",
    "# Create model metadata\n",
    "metadata = {\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'dataset_size': len(y),\n",
    "    'train_size': len(y_train),\n",
    "    'val_size': len(y_val),\n",
    "    'test_size': len(y_test),\n",
    "    'random_forest': {\n",
    "        'test_accuracy': float(test_acc),\n",
    "        'test_auc': float(test_auc),\n",
    "        'best_params': grid_search.best_params_\n",
    "    },\n",
    "    'cnn': {\n",
    "        'test_accuracy': float(test_acc_cnn),\n",
    "        'test_auc': float(test_auc_cnn),\n",
    "        'total_params': int(total_params)\n",
    "    },\n",
    "    'ensemble': {\n",
    "        'test_accuracy': float(ensemble_acc),\n",
    "        'test_auc': float(ensemble_auc)\n",
    "    },\n",
    "    'best_model': best_model_name,\n",
    "    'feature_names': feature_names\n",
    "}\n",
    "\n",
    "metadata_file = 'production_models/model_metadata.json'\n",
    "with open(metadata_file, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(f\"‚úÖ Model metadata saved: {metadata_file}\")\n",
    "\n",
    "print(f\"\\nüéâ All models exported successfully!\")\n",
    "print(f\"üìÅ Production files location: production_models/\")\n",
    "print(f\"\\nüìã Files created:\")\n",
    "print(f\"   üå≤ {rf_filename}\")\n",
    "print(f\"   ‚öôÔ∏è {scaler_filename}\")\n",
    "print(f\"   üß† {cnn_filename}\")\n",
    "print(f\"   üìù {feature_names_file}\")\n",
    "print(f\"   üìä {metadata_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download_models"
   },
   "source": [
    "## üì• 9. Download Production Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_files"
   },
   "outputs": [],
   "source": [
    "# Download production models\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "\n",
    "print(\"üì¶ Creating production models archive...\")\n",
    "\n",
    "# Create zip file with all production models\n",
    "zip_filename = 'cekajayuk_production_models.zip'\n",
    "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
    "    # Add all files from production_models directory\n",
    "    for file_path in Path('production_models').glob('*'):\n",
    "        if file_path.is_file():\n",
    "            zipf.write(file_path, file_path.name)\n",
    "            print(f\"   Added: {file_path.name}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Archive created: {zip_filename}\")\n",
    "print(f\"üìä Archive size: {os.path.getsize(zip_filename) / (1024*1024):.2f} MB\")\n",
    "\n",
    "# Download the zip file\n",
    "print(\"\\nüì• Downloading production models...\")\n",
    "files.download(zip_filename)\n",
    "\n",
    "print(\"\\nüéâ Download completed!\")\n",
    "print(\"\\nüìã Next Steps:\")\n",
    "print(\"1. Extract the downloaded zip file\")\n",
    "print(\"2. Copy model files to your CekAjaYuk project's 'models/' directory\")\n",
    "print(\"3. Update your backend to use these production models\")\n",
    "print(\"4. Test the models with your backend API\")\n",
    "\n",
    "print(\"\\nüöÄ Your CekAjaYuk models are ready for production!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
